{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a Model as a Web Service\n",
    "\n",
    "It's no good being able to create an accurate model if you can't deploy it for use in an application or service. In this notebook, we'll explore the *Azure Machine Learning Service* and the associated *Azure Machine Learning SDK*; which together enable you to train, deploy, and manage machine learning models at scale.\n",
    "\n",
    "To use Azure Machine Learning, you're going to need an Azure subscription. If you don't already have one, you can sign up for a free trial at https://azure.microsoft.com/Account/Free.\n",
    "\n",
    "*Note: Azure Machine Learning provides a whole range of functionality to help you through the entire lifecycle of model development, training, evaluation, deployment, and management. We're going to focus on using it to deploy a trained model; but you can use it to do much, much more!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Brief Introduction to Containers\n",
    "When you access a web site or a software service across the internet, you're probably dimly aware that somewhere, the code for the service is hosted on a *server*. We tend to think of servers as being physical computers, but in recent years there's been a growth in *virtualization* technologies so that a computer can be virtualized in software, and multiple *virtual machines* can be hosted on a single physical server.\n",
    "\n",
    "Virtual machines (VMs) are useful - in fact, the Azure Data Science Virtual Machine (DSVM) is a good example of a VM that enables you to provision a computer that contains the operating system (OS) and all the software applications you need to work with data and build machine learning models, and then you can delete the VM when you're finished with it so that you only pay for what you use - very cool!\n",
    "\n",
    "However, it seems wasteful to provision a complete virtual machine, including the full OS and applications, just to host a simple software service - especially if you need to support multiple services, each one consuming its own VM. *Containers* are an evolutionary step beyond VMs. They contain only the OS components that are required for the specific software service they need to host. This makes them very small compared to full VMs, which in turn means that they're portable, and quick to deploy and start up.\n",
    "\n",
    "Containers themselves are hosted in a container environment that provides all the common services and OS functionality they require. During development, this environment is often a locally installed system called *Docker*. When hosting a service in the cloud however, you can use container services such as *Azure Container Instances* (ACI), which is useful for lightweight hosting and testing of containerized services; or *Azure Kubernetes Services*, which provides a scalable and highly-available environment for managing clusters of containers, based on the industry standard *Kubernetes* container hosting platform.\n",
    "\n",
    "In the rest of this notebook, we'll examine how you can use Azure Machine Learning Services to prepare a container image for your machine learning model, and deploy your model as a containerized web service that can be consumed by other applications that connect to it over an HTTP REST endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classification model\n",
    "Let's start by training a simple classification model so that we have something to deploy.\n",
    "If you've viewed the previous sample notebooks in this hack, this should be pretty familiar - we're going to use PyTorch to train a simple shape classifier.\n",
    "\n",
    "First, we'll install the latest version of PyTorch and import the libraries we'll use to train and test the model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch\n",
    "import sys\n",
    "! {sys.executable} -m pip install --upgrade torch\n",
    "! {sys.executable} -m pip install --upgrade torchvision\n",
    "\n",
    "# Import PyTorch libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)\n",
    "\n",
    "# Other libraries we'll use\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll generate some images of geometric shapes with which to train and validate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a random image (of a square, circle, or triangle)\n",
    "def create_image (size, shape):\n",
    "    from random import randint\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageDraw\n",
    "    \n",
    "    xy1 = randint(10,40)\n",
    "    xy2 = randint(60,100)\n",
    "    col = (randint(0,200), randint(0,200), randint(0,200))\n",
    "\n",
    "    img = Image.new(\"RGB\", size, (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if shape == 'circle':\n",
    "        draw.ellipse([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    elif shape == 'square':\n",
    "        draw.rectangle([(xy1,xy1), (xy2,xy2)], fill=col)\n",
    "    else: # triangle\n",
    "        draw.polygon([(xy1,xy1), (xy2,xy2), (xy2,xy1)], fill=col)\n",
    "    del draw\n",
    "    \n",
    "    return np.array(img)\n",
    "    return np.array(img)\n",
    "\n",
    "# function to create a dataset of images\n",
    "def generate_image_data (classes, size, cases, img_dir):\n",
    "    import os, shutil\n",
    "    from PIL import Image\n",
    "    \n",
    "    if os.path.exists(img_dir):\n",
    "        replace_folder = input(\"Image folder already exists. Enter Y to replace it (this can take a while!). \\n\")\n",
    "        if replace_folder == \"Y\":\n",
    "            print(\"Deleting old images...\")\n",
    "            shutil.rmtree(img_dir)\n",
    "        else:\n",
    "            return # Quit - no need to replace existing images\n",
    "    os.makedirs(img_dir)\n",
    "    print(\"Generating new images...\")\n",
    "    i = 0\n",
    "    while(i < (cases - 1) / len(classes)):\n",
    "        if (i%25 == 0):\n",
    "            print(\"Progress:{:.0%}\".format((i*len(classes))/cases))\n",
    "        i += 1\n",
    "        for classname in classes:\n",
    "            img = Image.fromarray(create_image(size, classname))\n",
    "            saveFolder = os.path.join(img_dir,classname)\n",
    "            if not os.path.exists(saveFolder):\n",
    "                os.makedirs(saveFolder)\n",
    "            imgFileName = os.path.join(saveFolder, classname + str(i) + '.jpg')\n",
    "            try:\n",
    "                img.save(imgFileName)\n",
    "            except:\n",
    "                try:\n",
    "                    # Retry (resource constraints in Azure notebooks can cause occassional disk access errors)\n",
    "                    img.save(imgFileName)\n",
    "                except:\n",
    "                    # We gave it a shot - time to move on with our lives\n",
    "                    print(\"Error saving image\", imgFileName)\n",
    "                    \n",
    "# Function to ingest data using training and test loaders\n",
    "def load_dataset(data_path):\n",
    "    # Load all of the images\n",
    "    transformation = transforms.Compose([\n",
    "        # transform to tensors\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize the pixel values (in R, G, and B channels)\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    full_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        transform=transformation\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Split into training (70% and testing (30%) datasets)\n",
    "    train_size = int(0.7 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    \n",
    "    # define a loader for the training data we can iterate through in 50-image batches\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=50,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # define a loader for the testing data we can iterate through in 50-image batches\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=50,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "        \n",
    "    return train_loader, test_loader\n",
    "            \n",
    "# Our classes will be circles, squares, and triangles\n",
    "classnames = ['circle', 'square', 'triangle']\n",
    "\n",
    "# All images will be 128x128 pixels\n",
    "img_size = (128,128)\n",
    "\n",
    "# We'll store the images in a folder named 'shapes'\n",
    "folder_name = 'shapes'\n",
    "\n",
    "# Generate 1200 random images.\n",
    "generate_image_data(classnames, img_size, 1200, folder_name)\n",
    "\n",
    "# Now load the images from the shapes folder\n",
    "print(\"Loading image files in %s folder...\" % folder_name)\n",
    "data_path = folder_name + '/'\n",
    "\n",
    "# Get the iterative dataloaders for test and training data\n",
    "train_loader, test_loader = load_dataset(data_path)\n",
    "\n",
    "# Get the class names\n",
    "classes = os.listdir(data_path)\n",
    "classes.sort()\n",
    "print(\"Data loaded. \\n Class names: \", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural net class\n",
    "class Net(nn.Module):\n",
    "    # Constructor\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Our images are RGB, so input channels = 3. We'll apply 12 filters in the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # We'll apply max pooling with a kernel size of 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # A second convolutional layer takes 12 input channels, and generates 24 outputs\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # A drop layer deletes 20% of the features to help prevent overfitting\n",
    "        self.drop = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        # Our 128x128 image tensors will be pooled twice with a kernel size of 2. 128/2/2 is 32.\n",
    "        # So our feature tensors are now 32 x 32, and we've generated 24 of them\n",
    "        # We need to flatten these and feed them to a fully-connected layer\n",
    "        # to map them to  the probability for each class\n",
    "        self.fc = nn.Linear(in_features=32 * 32 * 24, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use a relu activation function after layer 1 (convolution 1 and pool)\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "      \n",
    "        # Use a relu activation function after layer 2 (convolution 2 and pool)\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        \n",
    "        # Select some features to drop after the 3rd convolution to prevent overfitting\n",
    "        x = F.relu(self.drop(x))\n",
    "        \n",
    "        # Only drop the features if this is a training pass\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 32 * 32 * 24)\n",
    "        # Feed to fully-connected layer to predict class\n",
    "        x = self.fc(x)\n",
    "        # Return class probabilities via a softmax function \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch)\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Use the CPU or GPU as appropriate\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = loss_criteria(output, target)\n",
    "        \n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print metrics for every 10 batches so we see some progress\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Training set [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(\n",
    "                batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "    # return average loss for the epoch\n",
    "    return train_loss / len(train_loader.dataset)\n",
    "            \n",
    "            \n",
    "def test(model, device, test_loader):\n",
    "    # Switch the model to evaluation mode (so we don't backpropagate or drop)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += loss_criteria(output, target).item()\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += torch.sum(target==predicted).item()\n",
    "\n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # return average loss for the epoch\n",
    "    return test_loss\n",
    "    \n",
    "# Now Use the train and test functions to train and test the model    \n",
    "\n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available()):\n",
    "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
    "    device = \"cuda\"\n",
    "print('Training on', device)\n",
    "\n",
    "# Create an instance of the model class and allocate it to the device\n",
    "model = Net(num_classes=len(classnames)).to(device)\n",
    "\n",
    "# Use an \"Adam\" optimizer to adjust weights\n",
    "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Specify the loss criteria\n",
    "loss_criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Track metrics in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "# Train over 5 epochs (in a real scenario, you'd likely use many more)\n",
    "epochs = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "        test_loss = test(model, device, test_loader)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and test the model locally\n",
    "OK, so we now have a trained shape classification model. Let's save it as a local file (well, local to the Azure Notebooks library anyway), and then load and test it; just to satisfy ourselves that it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the class of an image\n",
    "def predict_image(classifier, image_array):\n",
    "    import torch.utils.data as utils\n",
    "    import numpy as np\n",
    "    \n",
    "    # Set the classifer model to evaluation mode\n",
    "    classifier.eval()\n",
    "    \n",
    "    # Apply the same transformations as we did for the training images\n",
    "    transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Preprocess the image\n",
    "    image_tensor = torch.stack([transformation(image).float() for image in image_array])\n",
    "\n",
    "    # Turn the input into a Variable\n",
    "    input_features = Variable(image_tensor)\n",
    "\n",
    "    # Predict the class of the image\n",
    "    predictions = classifier(input_features)\n",
    "    \n",
    "    predicted_classes = []\n",
    "    for prediction in predictions.data.numpy():\n",
    "        class_idx = np.argmax(prediction)\n",
    "        predicted_classes.append(classes[class_idx])\n",
    "    return np.array(predicted_classes)\n",
    "\n",
    "# Save the model weights\n",
    "model_file = 'shape-classifier.pth'\n",
    "torch.save(model.state_dict(), model_file)\n",
    "print(\"Model saved.\")\n",
    "\n",
    "# Delete the existing model variable\n",
    "del model\n",
    "\n",
    "# Create a new model and load the weights\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "print(\"New model created from saved weights\")\n",
    "\n",
    "\n",
    "# Now let's try it with a new image\n",
    "from random import randint\n",
    "\n",
    "# Create a random test image\n",
    "img = create_image ((128,128), classes[randint(0, len(classes)-1)])\n",
    "plt.imshow(img)\n",
    "\n",
    "# Create an array of (1) images to match the expected input format\n",
    "image_array = img.reshape(1, img.shape[0], img.shape[1], img.shape[2]).astype('float32')\n",
    "\n",
    "predicted_classes = predict_image(model, image_array)\n",
    "print(predicted_classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as though we have a working model. Now we're ready to use Azure Machine Learning to deploy it as a web service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure Machine Learning workspace\n",
    "\n",
    "To use Azure Machine Learning, you'll need to create a workspace in your Azure subscription.\n",
    "\n",
    "Your Azure subscription is identified by a subscription ID. To find this:\n",
    "1. Sign into the Azure portal at https://portal.azure.com.\n",
    "2. On the menu tab on the left, click &#128273; **Subscriptions**.\n",
    "3. View the list of your subscriptions and copy the ID for the subscription you want to use.\n",
    "4. Paste the subscription ID into the code below, and then run the cell to set the variable - you will use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace YOUR_SUBSCRIPTION_ID in the following variable assignment:\n",
    "SUBSCRIPTION_ID = 'YOUR_SUBSCRIPTION_ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy the model file as a web service, we'll use the Azure Machine Learning SDK.\n",
    "\n",
    "> Note: the Azure Machine Learning SDK is installed by default in Azure Notebooks and the Azure Data Science Virtual Machine, but you may want to ensure that it's upgraded to the latest version. If you're using your own Python environment, you'll need to install it using the instructions in the [Azure Machine Learning documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-create-workspace-with-python)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "! {sys.executable} -m pip install azureml-sdk --upgrade\n",
    "\n",
    "import azureml.core\n",
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To manage the deployment, we need an Azure ML workspace. Create one in your Azure subscription by running the following cell. If you're signed into Azure notebooks using the same credentials as your Azure subscription, you may be prompted to grant this notebooks project permission to use your Azure credentials. Otherwise, you'll be prompted to authenticate by entering a code at a given URL, so just click the link that's displayed and enter the specified code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.create(name='aml_workspace', # or another name of your choosing\n",
    "                      subscription_id=SUBSCRIPTION_ID,\n",
    "                      resource_group='aml_resource_group', # or another name of your choosing\n",
    "                      create_resource_group=True,\n",
    "                      location='eastus2' # or other supported Azure region\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a workspace, you can save the configuration so you can reconnect to it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Save the workspace config\n",
    "ws.write_config()\n",
    "\n",
    "# Reconnect to the workspace (if you're not already signed in, you'll be prompted to authenticate with a code as before)\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a *scoring* file\n",
    "Your web service will need some Python code to load the input data, get the model, and generate and return a prediction. We'll save this code in a *scoring* file that will be deployed to the web service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score_pytorch.py\n",
    "\n",
    "# create a scoring script that loads and infers from the model\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    try:\n",
    "        global model\n",
    "        MODEL_NAME = 'shape-classifier.pth'\n",
    "        # retieve the local path to the model using the model name\n",
    "        MODEL_PATH = Model.get_model_path(MODEL_NAME)\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        model = Net()\n",
    "        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})\n",
    "\n",
    "# REST API served by Azure ML supports json input\n",
    "def run(json_data):\n",
    "    try:\n",
    "        data = np.array(json.loads(json_data)['data']).astype('float32')\n",
    "        predictions = predict_image(model, data)\n",
    "        return json.dumps(predictions.tolist())\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})\n",
    "\n",
    "# Function to predict\n",
    "def predict_image(classifier, image_array):\n",
    "    import torch\n",
    "    import torch.utils.data as utils\n",
    "    from torchvision import transforms\n",
    "    from torch.autograd import Variable\n",
    "    import numpy\n",
    "    \n",
    "    classifier.eval()\n",
    "    \n",
    "    transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    image_tensor = torch.stack([transformation(image).float() for image in image_array])\n",
    "\n",
    "    input_features = Variable(image_tensor)\n",
    "    predictions = classifier(input_features)\n",
    "    \n",
    "    classnames = ['circle', 'square', 'triangle']\n",
    "    \n",
    "    predicted_classes = []\n",
    "    for prediction in predictions.data.numpy():\n",
    "        class_idx = np.argmax(prediction)\n",
    "        predicted_classes.append(classnames[class_idx])\n",
    "    return np.array(predicted_classes)\n",
    "    \n",
    "# Define the Net class as used for training so we can load the trained weights\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        self.drop = nn.Dropout2d(p=0.2)\n",
    "        self.fc = nn.Linear(in_features=32 * 32 * 24, out_features=num_classes)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        x = F.relu(self.drop(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = x.view(-1, 32 * 32 * 24)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an *environment* file\n",
    "The web service will be hosted in a container, and the container will need to install any Python dependencies when it gets initialized. In this case, our scoring code requires the **torch** and **torchvision** Python libraries, so we'll create a .yml file that tells the container host to install these into the environment along with the default libraries used by Azure ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"pytorch\")\n",
    "myenv.add_conda_package(\"torchvision\")\n",
    "myenv.add_channel(\"pytorch\")\n",
    "\n",
    "env_file = \"env_pytorch.yml\"\n",
    "\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a container image\n",
    "We're going to deploy the web service as a container, so we need to define a container image that includes our scoring file and denvironment dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score_pytorch.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = env_file,\n",
    "                                                  description = \"Container image for shape classification\",\n",
    "                                                  tags = {\"data\": \"shapes\", \"type\": \"classification\"}\n",
    "                                                 )\n",
    "print(image_config.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the web service deployment configuration\n",
    "We're going to deploy the containerized web service in the Azure Container Instance (ACI) service, so we need to specify the deployment configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                               memory_gb = 1, \n",
    "                                               tags = {\"data\": \"shapes\", \"type\": \"classification\"},\n",
    "                                               description = 'shape classification service')\n",
    "print(aci_config.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the web service \n",
    "Now we're ready to deploy. We'll deploy the container a service named **aci-pytorch-shape-svc**.\n",
    "The deployment process includes the following steps:\n",
    "1. Register the model file in the Azure Machine Learning service (this also uploads the local model file to your Azure Machine Learning service so it can be deployed to a container)\n",
    "2. Create a container image for the web service, based on the configuration specified previously. This image will be used to instantiate the service.\n",
    "3. Create a service by deploying the container image (in this case to ACI - other hosts are available!)\n",
    "4. Verify the status of the deployed service.\n",
    "\n",
    "> For more information about Azure Container Instances, see https://azure.microsoft.com/en-us/services/container-instances.\n",
    "\n",
    "This will take some time. When deployment has completed successfully, you'll see a status of **Healthy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service_name = 'aci-pytorch-shape-svc'\n",
    "service = Webservice.deploy(deployment_config = aci_config,\n",
    "                                image_config = image_config,\n",
    "                                model_paths = [model_file],\n",
    "                                name = service_name,\n",
    "                                workspace = ws)\n",
    "\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the web service\n",
    "With the service deployed, now we can test it by using it to predict the shape of a new image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from random import randint\n",
    "\n",
    "# Create a random test image\n",
    "img = create_image ((128,128), classes[randint(0, len(classes)-1)])\n",
    "plt.imshow(img)\n",
    "\n",
    "# Modify the image data to create an array of 1 image, matching the format of the training features\n",
    "input_array = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "\n",
    "# Convert the array to JSON format\n",
    "input_json = json.dumps({\"data\": input_array.tolist()})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "classname = json.loads(predictions)[0]\n",
    "print('The image is a', classname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also send a batch of images to the service, and get back a prediction for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create three random test images\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "images = []\n",
    "i = 0\n",
    "while(i < 3):  \n",
    "    # Create a new image\n",
    "    img = create_image((128,128), classes[randint(0, len(classes)-1)])\n",
    "    # Plot the image\n",
    "    a=fig.add_subplot(1,3,i + 1)\n",
    "    imgplot = plt.imshow(img)\n",
    "    # Add the image to an array to be submitted as a batch\n",
    "    images.append(img.tolist())\n",
    "    i += 1\n",
    "\n",
    "# Convert the array to JSON format\n",
    "input_json = json.dumps({\"data\": images})\n",
    "\n",
    "# Call the web service, passing the input data\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted classes\n",
    "print(json.loads(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Web Service from Other Applications\n",
    "The code above uses the Azure ML SDK to connect to the containerized web service and use it to generate predictions from your image classification model. In production, the model is likely to be consumed by business applications that make HTTP requests to the web service.\n",
    "\n",
    "Let's determine the URL to which these applications must submit their requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the endpoint URI, an application can simply make an HTTP request, sending the image data in JSON (or binary) format, and receive back the predicted class(es)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests\n",
    "import json\n",
    "from random import randint\n",
    "\n",
    "# Create a random test image\n",
    "img = create_image ((128,128), classes[randint(0, len(classes)-1)])\n",
    "plt.imshow(img)\n",
    "\n",
    "# Create an array of (1) images to match the expected input format\n",
    "image_array = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": image_array.tolist()})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "print(json.loads(predictions.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the Service\n",
    "When we're finished with the service, we can delete it to avoid incurring charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()\n",
    "print(\"Service deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you're finished with the workspace, you can delete that too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = ws.resource_group\n",
    "ws.delete()\n",
    "print(\"Workspace deleted. You should delete the '%s' resource group in your Azure subscription.\" % rg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn more\n",
    "Take a look at the Azure Machine Learning documentation at https://docs.microsoft.com/en-us/azure/machine-learning/service/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
